{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author's description:\n",
    "\n",
    "Auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator.\n",
    "\n",
    "Auto-sklearn frees a machine learning user from algorithm selection and hyperparameter tuning. It leverages recent advantages in Bayesian optimization, meta-learning and ensemble construction. Learn more about the technology behind auto-sklearn by reading our paper published at [NeurIPS 2015](https://proceedings.neurips.cc/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf).\n",
    "\n",
    "#### Useful links:\n",
    "\n",
    "[Install Link](https://automl.github.io/auto-sklearn/master/installation.html)  \n",
    "[git](https://github.com/automl/auto-sklearn)  \n",
    "[Manual](https://automl.github.io/auto-sklearn/master/manual.html)  \n",
    "[Examples](https://automl.github.io/auto-sklearn/master/examples/index.html)  \n",
    "[Parallel Instances](https://automl.github.io/auto-sklearn/master/examples/60_search/example_parallel_manual_spawning_cli.html#sphx-glr-examples-60-search-example-parallel-manual-spawning-cli-py)  \n",
    "[Parallel Runs on One Machine](https://automl.github.io/auto-sklearn/master/examples/60_search/example_parallel_n_jobs.html#sphx-glr-examples-60-search-example-parallel-n-jobs-py)  \n",
    "[Model Explanations](https://automl.github.io/auto-sklearn/master/examples/40_advanced/example_inspect_predictions.html#sphx-glr-examples-40-advanced-example-inspect-predictions-py)  \n",
    "[Feature Types](https://automl.github.io/auto-sklearn/master/examples/40_advanced/example_feature_types.html#sphx-glr-examples-40-advanced-example-feature-types-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto-sklearn builds ensembles, provides good control of the auto-ML run details, and makes exporting easy due to its scikit-learn foundations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install auto-sklearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install auto-sklearn==0.6.0 --user\n",
    "\"\"\"\n",
    "original verision of auto-sklearn used\n",
    "did not capture original versions of other libraries like sklearn\n",
    "doesn't work on a new compute environment due to version mismatches\n",
    "best approach is to try on current latest versions of everything\n",
    "and then freeze all the package versions once it is working again\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *---You may need to restart the kernel after install and run again starting here---*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there can be a lot of warnings in auto-sklearn\n",
    "#especially if you overwrite existing files\n",
    "#turning off for demo purposes\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the classification function\n",
    "\n",
    "auto-sklearn is mostly a wrapper around scikit-learn. It was not the intention of the authors to allow user control over details such as the modeling algorithm and typical hyper-parameter choices. Control is several layers deep in the [SMAC](https://automl.github.io/SMAC3/master/) space and scenario settings. The user can control the time is takes to build the ensemble, the resampling strategy and the parallelization of the work across CPUs on the machine. These will be demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoSklearnClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtime_left_for_this_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_run_time_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_configurations_via_metalearning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_nbest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_models_on_disc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3072\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minclude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'holdout'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresampling_strategy_arguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtmp_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelete_tmp_folder_after_terminate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdask_client\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_evaluator_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_smac_object_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msmac_scenario_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogging_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscoring_functions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScorer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mload_models\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_trials_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      This class implements the classification task.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Parameters\n",
       "----------\n",
       "time_left_for_this_task : int, optional (default=3600)\n",
       "    Time limit in seconds for the search of appropriate\n",
       "    models. By increasing this value, *auto-sklearn* has a higher\n",
       "    chance of finding better models.\n",
       "\n",
       "per_run_time_limit : int, optional (default=1/10 of time_left_for_this_task)\n",
       "    Time limit for a single call to the machine learning model.\n",
       "    Model fitting will be terminated if the machine learning\n",
       "    algorithm runs over the time limit. Set this value high enough so\n",
       "    that typical machine learning algorithms can be fit on the\n",
       "    training data.\n",
       "\n",
       "initial_configurations_via_metalearning : int, optional (default=25)\n",
       "    Initialize the hyperparameter optimization algorithm with this\n",
       "    many configurations which worked well on previously seen\n",
       "    datasets. Disable if the hyperparameter optimization algorithm\n",
       "    should start from scratch.\n",
       "\n",
       "ensemble_size : int, optional (default=50)\n",
       "    Number of models added to the ensemble built by *Ensemble\n",
       "    selection from libraries of models*. Models are drawn with\n",
       "    replacement. If set to ``0`` no ensemble is fit.\n",
       "\n",
       "ensemble_nbest : int, optional (default=50)\n",
       "    Only consider the ``ensemble_nbest`` models when building an\n",
       "    ensemble.\n",
       "\n",
       "max_models_on_disc: int, optional (default=50),\n",
       "    Defines the maximum number of models that are kept in the disc.\n",
       "    The additional number of models are permanently deleted. Due to the\n",
       "    nature of this variable, it sets the upper limit on how many models\n",
       "    can be used for an ensemble.\n",
       "    It must be an integer greater or equal than 1.\n",
       "    If set to None, all models are kept on the disc.\n",
       "\n",
       "seed : int, optional (default=1)\n",
       "    Used to seed SMAC. Will determine the output file names.\n",
       "\n",
       "memory_limit : int, optional (3072)\n",
       "    Memory limit in MB for the machine learning algorithm.\n",
       "    `auto-sklearn` will stop fitting the machine learning algorithm if\n",
       "    it tries to allocate more than ``memory_limit`` MB.\n",
       "\n",
       "    **Important notes:**\n",
       "\n",
       "    * If ``None`` is provided, no memory limit is set.\n",
       "    * In case of multi-processing, ``memory_limit`` will be *per job*, so the total usage is\n",
       "      ``n_jobs x memory_limit``.\n",
       "    * The memory limit also applies to the ensemble creation process.\n",
       "\n",
       "include : Optional[Dict[str, List[str]]] = None\n",
       "    If None, all possible algorithms are used.\n",
       "\n",
       "    Otherwise, specifies a step and the components that are included in search.\n",
       "    See ``/pipeline/components/<step>/*`` for available components.\n",
       "\n",
       "    Incompatible with parameter ``exclude``.\n",
       "\n",
       "    **Possible Steps**:\n",
       "\n",
       "    * ``\"data_preprocessor\"``\n",
       "    * ``\"balancing\"``\n",
       "    * ``\"feature_preprocessor\"``\n",
       "    * ``\"classifier\"`` - Only for when when using ``AutoSklearnClasssifier``\n",
       "    * ``\"regressor\"`` - Only for when when using ``AutoSklearnRegressor``\n",
       "\n",
       "    **Example**:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        include = {\n",
       "            'classifier': [\"random_forest\"],\n",
       "            'feature_preprocessor': [\"no_preprocessing\"]\n",
       "        }\n",
       "\n",
       "exclude : Optional[Dict[str, List[str]]] = None\n",
       "    If None, all possible algorithms are used.\n",
       "\n",
       "    Otherwise, specifies a step and the components that are excluded from search.\n",
       "    See ``/pipeline/components/<step>/*`` for available components.\n",
       "\n",
       "    Incompatible with parameter ``include``.\n",
       "\n",
       "    **Possible Steps**:\n",
       "\n",
       "    * ``\"data_preprocessor\"``\n",
       "    * ``\"balancing\"``\n",
       "    * ``\"feature_preprocessor\"``\n",
       "    * ``\"classifier\"`` - Only for when when using ``AutoSklearnClasssifier``\n",
       "    * ``\"regressor\"`` - Only for when when using ``AutoSklearnRegressor``\n",
       "\n",
       "    **Example**:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        exclude = {\n",
       "            'classifier': [\"random_forest\"],\n",
       "            'feature_preprocessor': [\"no_preprocessing\"]\n",
       "        }\n",
       "\n",
       "resampling_strategy : string or object, optional ('holdout')\n",
       "    how to to handle overfitting, might need 'resampling_strategy_arguments'\n",
       "\n",
       "    * 'holdout': 67:33 (train:test) split\n",
       "    * 'holdout-iterative-fit':  67:33 (train:test) split, calls iterative\n",
       "      fit where possible\n",
       "    * 'cv': crossvalidation, requires 'folds'\n",
       "    * 'cv-iterative-fit': crossvalidation, calls iterative fit where possible\n",
       "    * 'partial-cv': crossvalidation with intensification, requires\n",
       "      'folds'\n",
       "    * BaseCrossValidator object: any BaseCrossValidator class found\n",
       "                                in scikit-learn model_selection module\n",
       "    * _RepeatedSplits object: any _RepeatedSplits class found\n",
       "                              in scikit-learn model_selection module\n",
       "    * BaseShuffleSplit object: any BaseShuffleSplit class found\n",
       "                              in scikit-learn model_selection module\n",
       "\n",
       "resampling_strategy_arguments : dict, optional if 'holdout' (train_size default=0.67)\n",
       "    Additional arguments for resampling_strategy:\n",
       "\n",
       "    * ``train_size`` should be between 0.0 and 1.0 and represent the\n",
       "      proportion of the dataset to include in the train split.\n",
       "    * ``shuffle`` determines whether the data is shuffled prior to\n",
       "      splitting it into train and validation.\n",
       "\n",
       "    Available arguments:\n",
       "\n",
       "    * 'holdout': {'train_size': float}\n",
       "    * 'holdout-iterative-fit':  {'train_size': float}\n",
       "    * 'cv': {'folds': int}\n",
       "    * 'cv-iterative-fit': {'folds': int}\n",
       "    * 'partial-cv': {'folds': int, 'shuffle': bool}\n",
       "    * BaseCrossValidator or _RepeatedSplits or BaseShuffleSplit object: all arguments\n",
       "      required by chosen class as specified in scikit-learn documentation.\n",
       "      If arguments are not provided, scikit-learn defaults are used.\n",
       "      If no defaults are available, an exception is raised.\n",
       "      Refer to the 'n_splits' argument as 'folds'.\n",
       "\n",
       "tmp_folder : string, optional (None)\n",
       "    folder to store configuration output and log files, if ``None``\n",
       "    automatically use ``/tmp/autosklearn_tmp_$pid_$random_number``\n",
       "\n",
       "delete_tmp_folder_after_terminate: bool, optional (True)\n",
       "    remove tmp_folder, when finished. If tmp_folder is None\n",
       "    tmp_dir will always be deleted\n",
       "\n",
       "n_jobs : int, optional, experimental\n",
       "    The number of jobs to run in parallel for ``fit()``. ``-1`` means\n",
       "    using all processors. \n",
       "    \n",
       "    **Important notes**: \n",
       "    \n",
       "    * By default, Auto-sklearn uses one core. \n",
       "    * Ensemble building is not affected by ``n_jobs`` but can be controlled by the number \n",
       "      of models in the ensemble.\n",
       "    * ``predict()`` is not affected by ``n_jobs`` (in contrast to most scikit-learn models)\n",
       "    * If ``dask_client`` is ``None``, a new dask client is created.\n",
       "\n",
       "dask_client : dask.distributed.Client, optional\n",
       "    User-created dask client, can be used to start a dask cluster and then\n",
       "    attach auto-sklearn to it.\n",
       "\n",
       "disable_evaluator_output: bool or list, optional (False)\n",
       "    If True, disable model and prediction output. Cannot be used\n",
       "    together with ensemble building. ``predict()`` cannot be used when\n",
       "    setting this True. Can also be used as a list to pass more\n",
       "    fine-grained information on what to save. Allowed elements in the\n",
       "    list are:\n",
       "\n",
       "    * ``'y_optimization'`` : do not save the predictions for the\n",
       "      optimization/validation set, which would later on be used to build\n",
       "      an ensemble.\n",
       "    * ``model`` : do not save any model files\n",
       "\n",
       "smac_scenario_args : dict, optional (None)\n",
       "    Additional arguments inserted into the scenario of SMAC. See the\n",
       "    `SMAC documentation <https://automl.github.io/SMAC3/master/pages/details/scenario.html>`_\n",
       "    for a list of available arguments.\n",
       "\n",
       "get_smac_object_callback : callable\n",
       "    Callback function to create an object of class\n",
       "    `smac.optimizer.smbo.SMBO <https://automl.github.io/SMAC3/master/apidoc/smac.optimizer.smbo.html>`_.\n",
       "    The function must accept the arguments ``scenario_dict``,\n",
       "    ``instances``, ``num_params``, ``runhistory``, ``seed`` and ``ta``.\n",
       "    This is an advanced feature. Use only if you are familiar with\n",
       "    `SMAC <https://automl.github.io/SMAC3/master/index.html>`_.\n",
       "\n",
       "logging_config : dict, optional (None)\n",
       "    dictionary object specifying the logger configuration. If None,\n",
       "    the default logging.yaml file is used, which can be found in\n",
       "    the directory ``util/logging.yaml`` relative to the installation.\n",
       "\n",
       "metadata_directory : str, optional (None)\n",
       "    path to the metadata directory. If None, the default directory\n",
       "    (autosklearn.metalearning.files) is used.\n",
       "\n",
       "metric : Scorer, optional (None)\n",
       "    An instance of :class:`autosklearn.metrics.Scorer` as created by\n",
       "    :meth:`autosklearn.metrics.make_scorer`. These are the `Built-in\n",
       "    Metrics`_.\n",
       "    If None is provided, a default metric is selected depending on the task.\n",
       "\n",
       "scoring_functions : List[Scorer], optional (None)\n",
       "    List of scorers which will be calculated for each pipeline and results will be\n",
       "    available via ``cv_results``\n",
       "\n",
       "load_models : bool, optional (True)\n",
       "    Whether to load the models after fitting Auto-sklearn.\n",
       "   \n",
       "get_trials_callback: callable\n",
       "    Callback function to create an object of subclass defined in module\n",
       "    `smac.callbacks <https://automl.github.io/SMAC3/master/apidoc/smac.callbacks.html>`_.\n",
       "    This is an advanced feature. Use only if you are familiar with\n",
       "    `SMAC <https://automl.github.io/SMAC3/master/index.html>`_.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "\n",
       "cv_results_ : dict of numpy (masked) ndarrays\n",
       "    A dict with keys as column headers and values as columns, that can be\n",
       "    imported into a pandas ``DataFrame``.\n",
       "\n",
       "    Not all keys returned by scikit-learn are supported yet.\n",
       "\n",
       "performance_over_time_ : pandas.core.frame.DataFrame\n",
       "    A ``DataFrame`` containing the models performance over time data. Can be\n",
       "    used for plotting directly. Please refer to the example\n",
       "    :ref:`Train and Test Inputs <sphx_glr_examples_40_advanced_example_pandas_train_test.py>`.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.8/site-packages/autosklearn/estimators.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?autosklearn.classification.AutoSklearnClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the heart disease dataset\n",
    "\n",
    "Note that in this cell we are calling **sklearn.model_selection.train_test_split()** twice and creating two sets of heart disease (hd) data for model fitting and testing. One is for the hd data without one hot encoding (ohe) and the other has the ohe columns. \n",
    "\n",
    "auto-sklearn accepts a list of categorical features and has several methods for treating categorical data. In this notebook we try both approaches - building ohe columns ourselves and letting auto-sklearn do its thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/mnt/data/raw/heart.csv\n",
    "\n",
    "attribute documentation:\n",
    "      age: age in years\n",
    "      sex: sex (1 = male; 0 = female)\n",
    "      cp: chest pain type\n",
    "        -- Value 1: typical angina\n",
    "        -- Value 2: atypical angina\n",
    "        -- Value 3: non-anginal pain\n",
    "        -- Value 4: asymptomatic\n",
    "     trestbps: resting blood pressure (in mm Hg on admission to the \n",
    "        hospital)\n",
    "     chol: serum cholestoral in mg/dl\n",
    "     fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "     restecg: resting electrocardiographic results\n",
    "        -- Value 0: normal\n",
    "        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n",
    "                    elevation or depression of > 0.05 mV)\n",
    "        -- Value 2: showing probable or definite left ventricular hypertrophy\n",
    "                    by Estes' criteria\n",
    "     thalach: maximum heart rate achieved\n",
    "     exang: exercise induced angina (1 = yes; 0 = no)\n",
    "     oldpeak = ST depression induced by exercise relative to rest\n",
    "     slope: the slope of the peak exercise ST segment\n",
    "        -- Value 1: upsloping\n",
    "        -- Value 2: flat\n",
    "        -- Value 3: downsloping\n",
    "     ca: number of major vessels (0-3) colored by flourosopy\n",
    "     thal: \n",
    "         3 = normal; \n",
    "         6 = fixed defect; \n",
    "         7 = reversable defect\n",
    "     target: diagnosis of heart disease (angiographic disease status)\n",
    "        -- Value 0: < 50% diameter narrowing\n",
    "        -- Value 1: > 50% diameter narrowing\n",
    " '''\n",
    "\n",
    "#load and clean the data----------------------\n",
    "\n",
    "#column names\n",
    "names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang', \\\n",
    "         'oldpeak','slope','ca','thal','target']\n",
    "\n",
    "#load data from Domino project directory\n",
    "hd_data = pd.read_csv(\"./data/raw/heart.csv\", header=None, names=names)\n",
    "\n",
    "#in case some data comes in as string\n",
    "#convert to numeric and coerce errors to NaN\n",
    "for col in hd_data.columns:  # Iterate over chosen columns\n",
    "    hd_data[col] = pd.to_numeric(hd_data[col], errors='coerce')\n",
    "    \n",
    "#drop nulls\n",
    "hd_data.dropna(inplace=True)\n",
    "\n",
    "#non-ohe data---------------------------------\n",
    "   \n",
    "#load the X and y set as a numpy array\n",
    "X_hd = hd_data.drop('target', axis=1).values\n",
    "y_hd = hd_data['target'].values\n",
    "\n",
    "#build the train and test sets\n",
    "X_hd_train, X_hd_test, y_hd_train, y_hd_test = \\\n",
    "    sklearn.model_selection.train_test_split(X_hd, y_hd, random_state=12)\n",
    "\n",
    "#now do ohe-----------------------------------\n",
    "\n",
    "#function to do one hot encoding for categorical columns\n",
    "def create_dummies(data, cols, drop1st=True):\n",
    "    for c in cols:\n",
    "        dummies_df = pd.get_dummies(data[c], prefix=c, drop_first=drop1st)  \n",
    "        data=pd.concat([data, dummies_df], axis=1)\n",
    "        data = data.drop([c], axis=1)\n",
    "    return data\n",
    "\n",
    "cat_cols = ['cp', 'restecg', 'slope', 'ca', 'thal']\n",
    "hd_data = create_dummies(hd_data, cat_cols)\n",
    "    \n",
    "#load the X and y set as a numpy array\n",
    "X_hd_ohe = hd_data.drop('target', axis=1).values\n",
    "y_hd_ohe = hd_data['target'].values\n",
    "\n",
    "#build the train and test sets\n",
    "X_hd_ohe_train, X_hd_ohe_test, y_hd_ohe_train, y_hd_ohe_test = \\\n",
    "    sklearn.model_selection.train_test_split(X_hd_ohe, y_hd_ohe, \\\n",
    "                                             random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model on ohe data with holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-09-01 21:34:53,098:Client-AutoML(1):heart_disease] Capping the per_run_time_limit to 29.0 to have time for a least 2 models in each process.\n",
      "CPU times: user 6.29 s, sys: 707 ms, total: 7 s\n",
      "Wall time: 59.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#build the auto-sklearn routine\n",
    "automl_hd_ohe = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60,\n",
    "    per_run_time_limit=30,\n",
    "    disable_evaluator_output=False,\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67}\n",
    ")\n",
    "\n",
    "#call it\n",
    "automl_hd_ohe.fit(X_hd_ohe_train, y_hd_ohe_train, \\\n",
    "                  dataset_name='heart_disease')\n",
    "\n",
    "#save the predicitons\n",
    "predictions_hd_ohe = automl_hd_ohe.predict(X_hd_ohe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting with autosklearn\n",
    "\n",
    "A common mistake is to call **fit_ensemble()** after already running **fit()**. **fit()** both optimizes the machine learning models and builds an ensemble out of them. To disable ensembling when running **fit()** (with parallel instances for example) set ensemble_size to 0. Then **fit_ensemble()** would be needed once all models have been built.\n",
    "\n",
    "To save fitted models, use typical [pickle procedures](https://scikit-learn.org/stable/modules/model_persistence.html#persistence-example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "Accuracy, sprint stats, and model details are available. \n",
    "\n",
    "Later we will run auto-sklearn in parallel. Note the number of models built here and compare it to the number built with parallelization turned on. \n",
    "\n",
    "The model details give you insight into what auto-sklearn is doing under the hood. You can see the modeling algorithm used and all the parameter settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.6973684210526315\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Sprint Stats:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.880000\n",
      "  Number of target algorithm runs: 24\n",
      "  Number of successful target algorithm runs: 23\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 1\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Model Details:\n",
      "{24: {'model_id': 24, 'rank': 1, 'cost': 0.12, 'ensemble_weight': 0.28, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64b4c10a30>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64b4c10be0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64b4c10190>, 'sklearn_classifier': AdaBoostClassifier(algorithm='SAMME',\n",
      "                   base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=0.13167493237005792, n_estimators=56,\n",
      "                   random_state=1)}, 10: {'model_id': 10, 'rank': 2, 'cost': 0.1333333333333333, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64b4e9ea90>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64b4ba4040>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64b4ba4c70>, 'sklearn_classifier': MLPClassifier(activation='tanh', alpha=0.0001363185819149026, beta_1=0.999,\n",
      "              beta_2=0.9, early_stopping=True,\n",
      "              hidden_layer_sizes=(115, 115, 115),\n",
      "              learning_rate_init=0.00018009776276177523, max_iter=32,\n",
      "              n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)}, 13: {'model_id': 13, 'rank': 3, 'cost': 0.1333333333333333, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64b4e9e550>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64b4b27d60>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64b418ed00>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.4635442279519353,\n",
      "                               learning_rate=0.09809681787962342, max_iter=512,\n",
      "                               max_leaf_nodes=328, min_samples_leaf=2,\n",
      "                               n_iter_no_change=2, random_state=1,\n",
      "                               validation_fraction=None, warm_start=True)}, 4: {'model_id': 4, 'rank': 4, 'cost': 0.1466666666666666, 'ensemble_weight': 0.1, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64b4427c40>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64b4187a00>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64a98e3fd0>, 'sklearn_classifier': MLPClassifier(activation='tanh', alpha=2.5550223982458062e-06, beta_1=0.999,\n",
      "              beta_2=0.9, hidden_layer_sizes=(54, 54, 54),\n",
      "              learning_rate_init=0.00027271287919467994, max_iter=256,\n",
      "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
      "              verbose=0, warm_start=True)}, 9: {'model_id': 9, 'rank': 5, 'cost': 0.1466666666666666, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64b4b273a0>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64a98e37f0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f6495965790>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=2, min_samples_leaf=2,\n",
      "                       n_estimators=512, n_jobs=1, random_state=1,\n",
      "                       warm_start=True)}, 11: {'model_id': 11, 'rank': 6, 'cost': 0.17333333333333334, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64b4b30640>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f649adeafd0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f6495965190>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=17, min_samples_leaf=7,\n",
      "                       n_estimators=512, n_jobs=1, random_state=1,\n",
      "                       warm_start=True)}, 16: {'model_id': 16, 'rank': 7, 'cost': 0.17333333333333334, 'ensemble_weight': 0.12, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64b409f340>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f6490c22340>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f6490b6f8e0>, 'sklearn_classifier': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   learning_rate=0.046269426995092074, n_estimators=406,\n",
      "                   random_state=1)}, 15: {'model_id': 15, 'rank': 8, 'cost': 0.18666666666666665, 'ensemble_weight': 0.08, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64a9852af0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f6490ae6400>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f6490b4f6d0>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=15, n_estimators=512,\n",
      "                       n_jobs=1, random_state=1, warm_start=True)}, 6: {'model_id': 6, 'rank': 9, 'cost': 0.19999999999999996, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f6493200b80>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f6490bf1b80>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f6490beafd0>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.005326508887463406,\n",
      "                               learning_rate=0.060800813211425456, max_iter=512,\n",
      "                               max_leaf_nodes=6, min_samples_leaf=5,\n",
      "                               n_iter_no_change=5, random_state=1,\n",
      "                               validation_fraction=None, warm_start=True)}, 21: {'model_id': 21, 'rank': 10, 'cost': 0.19999999999999996, 'ensemble_weight': 0.16, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f6490a7ac40>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f648e47bf70>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f648e45e070>, 'sklearn_classifier': DecisionTreeClassifier(class_weight='balanced', max_depth=22,\n",
      "                       min_samples_leaf=4, min_samples_split=20,\n",
      "                       random_state=1)}, 22: {'model_id': 22, 'rank': 11, 'cost': 0.28, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f6490babfd0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f648e3e7190>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f648e3e7250>, 'sklearn_classifier': SVC(C=1198.7850746967626, cache_size=1936.3463541666667,\n",
      "    gamma=0.015219182148092949, max_iter=-1.0, random_state=1,\n",
      "    tol=0.040610448809956276)}, 20: {'model_id': 20, 'rank': 12, 'cost': 0.43999999999999995, 'ensemble_weight': 0.1, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f648e47b5b0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f648e322370>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f648e322460>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.0015246021799433245,\n",
      "                               learning_rate=0.051072202871981255, max_iter=32,\n",
      "                               max_leaf_nodes=377, min_samples_leaf=100,\n",
      "                               n_iter_no_change=17, random_state=1,\n",
      "                               validation_fraction=0.2801600670702926,\n",
      "                               warm_start=True)}}\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe))\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Sprint Stats:')\n",
    "print(automl_hd_ohe.sprint_statistics())\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Model Details:')\n",
    "print(automl_hd_ohe.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Do the same thing (build a model on ohe data with holdout) but this time with parallelization turned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-09-01 21:52:01,294:Client-AutoML(5):heart_disease] Capping the per_run_time_limit to 59.0 to have time for a least 2 models in each process.\n",
      "[ERROR] [2022-09-01 21:53:56,023:asyncio.events] \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 1427, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/comm/inproc.py\", line 211, in read\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 1435, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 1246, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 1276, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/comm/core.py\", line 315, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/opt/conda/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "CPU times: user 46.4 s, sys: 2.93 s, total: 49.3 s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#build the auto-sklearn routine\n",
    "automl_hd_ohe_p = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=120,\n",
    "    per_run_time_limit=60,\n",
    "    disable_evaluator_output=False,\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67},\n",
    "    \n",
    "    #turn on parallelization\n",
    "    n_jobs=4,\n",
    "    seed=5,\n",
    ")\n",
    "\n",
    "#call it\n",
    "automl_hd_ohe_p.fit(X_hd_ohe_train, y_hd_ohe_train, \\\n",
    "                    dataset_name='heart_disease')\n",
    "\n",
    "#save the predicitons\n",
    "predictions_hd_ohe_p = automl_hd_ohe_p.predict(X_hd_ohe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.6973684210526315\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Sprint Stats:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.893333\n",
      "  Number of target algorithm runs: 33\n",
      "  Number of successful target algorithm runs: 33\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe_p))\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Sprint Stats:')\n",
    "print(automl_hd_ohe_p.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details:\n",
      "{24: {'model_id': 24, 'rank': 1, 'cost': 0.10666666666666669, 'ensemble_weight': 0.5, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64a4b466d0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f646c284f10>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f646c2842e0>, 'sklearn_classifier': AdaBoostClassifier(algorithm='SAMME',\n",
      "                   base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=0.13167493237005792, n_estimators=56,\n",
      "                   random_state=5)}, 13: {'model_id': 13, 'rank': 2, 'cost': 0.1333333333333333, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64a4a8cca0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f648b948490>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f646c40ca60>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.4635442279519353,\n",
      "                               learning_rate=0.09809681787962342, max_iter=512,\n",
      "                               max_leaf_nodes=328, min_samples_leaf=2,\n",
      "                               n_iter_no_change=2, random_state=5,\n",
      "                               validation_fraction=None, warm_start=True)}, 32: {'model_id': 32, 'rank': 3, 'cost': 0.1333333333333333, 'ensemble_weight': 0.12, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f648c06cc10>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f646c201c40>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f646c201e80>, 'sklearn_classifier': AdaBoostClassifier(algorithm='SAMME',\n",
      "                   base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   learning_rate=0.0901404288021253, n_estimators=291,\n",
      "                   random_state=5)}, 27: {'model_id': 27, 'rank': 4, 'cost': 0.16000000000000003, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f648e80d220>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f646c435130>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f646c2dc670>, 'sklearn_classifier': SGDClassifier(alpha=0.06840329554889894, eta0=7.568166542222647e-06,\n",
      "              learning_rate='constant', loss='squared_hinge', max_iter=256,\n",
      "              penalty='l1', random_state=5, tol=0.0005064155967541273,\n",
      "              warm_start=True)}, 16: {'model_id': 16, 'rank': 5, 'cost': 0.17333333333333334, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f648b948160>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f648b94f520>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64a2674280>, 'sklearn_classifier': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   learning_rate=0.046269426995092074, n_estimators=406,\n",
      "                   random_state=5)}, 21: {'model_id': 21, 'rank': 6, 'cost': 0.19999999999999996, 'ensemble_weight': 0.1, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64a24d3520>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64a2674190>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64a2674a30>, 'sklearn_classifier': DecisionTreeClassifier(class_weight='balanced', max_depth=22,\n",
      "                       min_samples_leaf=4, min_samples_split=20,\n",
      "                       random_state=5)}, 22: {'model_id': 22, 'rank': 7, 'cost': 0.28, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f646c1b0a00>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f648ba32df0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f648ba327f0>, 'sklearn_classifier': SVC(C=1198.7850746967626, cache_size=1961.8411458333333,\n",
      "    gamma=0.015219182148092949, max_iter=-1.0, random_state=5,\n",
      "    tol=0.040610448809956276)}, 20: {'model_id': 20, 'rank': 8, 'cost': 0.43999999999999995, 'ensemble_weight': 0.14, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f648ba63100>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f648bd10d00>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f648bd10e80>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.0015246021799433245,\n",
      "                               learning_rate=0.051072202871981255, max_iter=32,\n",
      "                               max_leaf_nodes=377, min_samples_leaf=100,\n",
      "                               n_iter_no_change=17, random_state=5,\n",
      "                               validation_fraction=0.2801600670702926,\n",
      "                               warm_start=True)}, 30: {'model_id': 30, 'rank': 9, 'cost': 0.43999999999999995, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f646c4749a0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64a4a93640>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64a24bd490>, 'sklearn_classifier': PassiveAggressiveClassifier(C=1.1083888353882014, max_iter=32, random_state=5,\n",
      "                            tol=9.781483858446464e-05, warm_start=True)}}\n"
     ]
    }
   ],
   "source": [
    "print('Model Details:')\n",
    "print(automl_hd_ohe_p.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the breast cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "print(sklearn.datasets.load_breast_cancer()['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from sklearn\n",
    "X_bc, y_bc = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "#build the train and test sets\n",
    "X_bc_train, X_bc_test, y_bc_train, y_bc_test = \\\n",
    "    sklearn.model_selection.train_test_split(X_bc, y_bc, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model using holdout and parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-09-01 21:55:18,604:Client-AutoML(5):breast_cancer] Capping the per_run_time_limit to 29.0 to have time for a least 2 models in each process.\n",
      "[ERROR] [2022-09-01 21:56:08,656:asyncio.events] \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 1427, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/comm/inproc.py\", line 211, in read\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 1435, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 1246, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 1276, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/distributed/comm/core.py\", line 315, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/opt/conda/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "CPU times: user 5.75 s, sys: 618 ms, total: 6.37 s\n",
      "Wall time: 56.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#build the auto-sklearn routine\n",
    "automl_bc = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60,\n",
    "    per_run_time_limit=30,\n",
    "    disable_evaluator_output=False,\n",
    "    # 'holdout' with 'train_size'=0.67 is the default argument setting\n",
    "    # for AutoSklearnClassifier. It is explicitly specified in this example\n",
    "    # for demonstrational purpose.\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67},\n",
    "    n_jobs=4,\n",
    "    seed=5,\n",
    ")\n",
    "\n",
    "#call it\n",
    "automl_bc.fit(X_bc_train, y_bc_train, dataset_name='breast_cancer')\n",
    "\n",
    "#save the predicitons\n",
    "predictions_bc = automl_bc.predict(X_bc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.951048951048951\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Sprint Stats:\n",
      "auto-sklearn results:\n",
      "  Dataset name: breast_cancer\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.985816\n",
      "  Number of target algorithm runs: 21\n",
      "  Number of successful target algorithm runs: 17\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 4\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(sklearn.metrics.accuracy_score(y_bc_test, \\\n",
    "                                     predictions_bc))\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Sprint Stats:')\n",
    "print(automl_bc.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details:\n",
      "{3: {'model_id': 3, 'rank': 1, 'cost': 0.014184397163120588, 'ensemble_weight': 0.3, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f648ba57520>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f645541a910>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f645541af70>, 'sklearn_classifier': MLPClassifier(activation='tanh', alpha=0.0001363185819149026, beta_1=0.999,\n",
      "              beta_2=0.9, early_stopping=True,\n",
      "              hidden_layer_sizes=(115, 115, 115),\n",
      "              learning_rate_init=0.00018009776276177523, max_iter=32,\n",
      "              n_iter_no_change=32, random_state=5, verbose=0, warm_start=True)}, 7: {'model_id': 7, 'rank': 2, 'cost': 0.014184397163120588, 'ensemble_weight': 0.28, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f648b951fa0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f646c40c640>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f646c40ccd0>, 'sklearn_classifier': ExtraTreesClassifier(max_features=34, min_samples_leaf=3, min_samples_split=11,\n",
      "                     n_estimators=512, n_jobs=1, random_state=5,\n",
      "                     warm_start=True)}, 2: {'model_id': 2, 'rank': 3, 'cost': 0.021276595744680882, 'ensemble_weight': 0.08, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f646c241d00>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f648ba2f4f0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f648ba2f6d0>, 'sklearn_classifier': RandomForestClassifier(max_features=5, n_estimators=512, n_jobs=1,\n",
      "                       random_state=5, warm_start=True)}, 6: {'model_id': 6, 'rank': 4, 'cost': 0.021276595744680882, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f646c40c460>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f646c4501c0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64a4a82190>, 'sklearn_classifier': MLPClassifier(alpha=0.0017940473175767063, beta_1=0.999, beta_2=0.9,\n",
      "              early_stopping=True, hidden_layer_sizes=(101, 101),\n",
      "              learning_rate_init=0.0004684917334431039, max_iter=64,\n",
      "              n_iter_no_change=32, random_state=5, verbose=0, warm_start=True)}, 10: {'model_id': 10, 'rank': 5, 'cost': 0.028368794326241176, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f646c2d77c0>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64a4b52820>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64a4b1eeb0>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=4, min_samples_split=6,\n",
      "                       n_estimators=512, n_jobs=1, random_state=5,\n",
      "                       warm_start=True)}, 14: {'model_id': 14, 'rank': 6, 'cost': 0.028368794326241176, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f646c2de220>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64a2109190>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64a4c4d8e0>, 'sklearn_classifier': MLPClassifier(activation='tanh', alpha=2.5550223982458062e-06, beta_1=0.999,\n",
      "              beta_2=0.9, hidden_layer_sizes=(54, 54, 54),\n",
      "              learning_rate_init=0.00027271287919467994, max_iter=256,\n",
      "              n_iter_no_change=32, random_state=5, validation_fraction=0.0,\n",
      "              verbose=0, warm_start=True)}, 8: {'model_id': 8, 'rank': 7, 'cost': 0.03546099290780147, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64a4a87a00>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64a4c5a040>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64a4c3ffd0>, 'sklearn_classifier': RandomForestClassifier(max_features=2, min_samples_leaf=2, n_estimators=512,\n",
      "                       n_jobs=1, random_state=5, warm_start=True)}, 12: {'model_id': 12, 'rank': 8, 'cost': 0.03546099290780147, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64a4a9d730>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f64a4c36280>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f64a4c36f70>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.005326508887463406,\n",
      "                               learning_rate=0.060800813211425456, max_iter=512,\n",
      "                               max_leaf_nodes=6, min_samples_leaf=5,\n",
      "                               n_iter_no_change=5, random_state=5,\n",
      "                               validation_fraction=None, warm_start=True)}, 17: {'model_id': 17, 'rank': 9, 'cost': 0.03546099290780147, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f645543aee0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f643736c790>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f643703a130>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.4635442279519353,\n",
      "                               learning_rate=0.09809681787962342, max_iter=512,\n",
      "                               max_leaf_nodes=328, min_samples_leaf=2,\n",
      "                               n_iter_no_change=2, random_state=5,\n",
      "                               validation_fraction=None, warm_start=True)}, 5: {'model_id': 5, 'rank': 10, 'cost': 0.04255319148936165, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64a4c094c0>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f6437056910>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f6436f369a0>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=3, min_samples_leaf=2,\n",
      "                       n_estimators=512, n_jobs=1, random_state=5,\n",
      "                       warm_start=True)}, 9: {'model_id': 9, 'rank': 11, 'cost': 0.04255319148936165, 'ensemble_weight': 0.1, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f6437358d60>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f6436f36280>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f6436d95370>, 'sklearn_classifier': ExtraTreesClassifier(max_features=7, min_samples_split=10, n_estimators=512,\n",
      "                     n_jobs=1, random_state=5, warm_start=True)}, 18: {'model_id': 18, 'rank': 12, 'cost': 0.04255319148936165, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f64370c6520>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f6436d81370>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f6436cd3970>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=3, n_estimators=512,\n",
      "                       n_jobs=1, random_state=5, warm_start=True)}}\n"
     ]
    }
   ],
   "source": [
    "print('Model Details:')\n",
    "print(automl_bc.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Run and Accuracy Stats\n",
    "\n",
    "All in one place for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Heart Disease---------------\n",
      " \n",
      " \n",
      "Model stats HD Holdout:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.880000\n",
      "  Number of target algorithm runs: 24\n",
      "  Number of successful target algorithm runs: 23\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 1\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      " \n",
      "Accuracy score HD Holdout:\n",
      "0.6973684210526315\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Model stats HD Holdout Parallel:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.893333\n",
      "  Number of target algorithm runs: 33\n",
      "  Number of successful target algorithm runs: 33\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "Accuracy score HD Holdout Parallel:\n",
      "0.6973684210526315\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "-----------Breast Cancer---------------\n",
      " \n",
      " \n",
      "Model stats BC Holdout Parallel:\n",
      "auto-sklearn results:\n",
      "  Dataset name: breast_cancer\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.985816\n",
      "  Number of target algorithm runs: 21\n",
      "  Number of successful target algorithm runs: 17\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 4\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      " \n",
      "Accuracy score BC Holdout Parallel:\n",
      "0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------Heart Disease---------------\")\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print(\"Model stats HD Holdout:\")\n",
    "print(automl_hd_ohe.sprint_statistics())\n",
    "print(' ')\n",
    "print(\"Accuracy score HD Holdout:\")\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe))\n",
    "\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "\n",
    "print(\"Model stats HD Holdout Parallel:\")\n",
    "print(automl_hd_ohe_p.sprint_statistics())\n",
    "print(\"Accuracy score HD Holdout Parallel:\")\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe_p))\n",
    "\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "\n",
    "# #holdout parallel feat_type\n",
    "# print(\"Model stats HD Holdout Feature Type Parallel:\")\n",
    "# print(automl_hd_ft_p.sprint_statistics())\n",
    "# print(' ')\n",
    "# print(\"Accuracy score HD Holdout Feature Type Parallel:\")\n",
    "# print(sklearn.metrics.accuracy_score(y_hd_test, \\\n",
    "#                                      predictions_hd_ft_p))\n",
    "\n",
    "# print(' ')\n",
    "# print('-----------------------------------------')\n",
    "# print(' ')\n",
    "\n",
    "# #cross validation parallel\n",
    "# print(\"Model stats HD CV Parllel:\")\n",
    "# print(automl_hd_cv_p.sprint_statistics())\n",
    "# print(' ')\n",
    "# print(\"Accuracy score HD CV Parallel:\")\n",
    "# print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "#                                      predictions_hd_cv_p))\n",
    "\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print(\"-----------Breast Cancer---------------\")\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print(\"Model stats BC Holdout Parallel:\")\n",
    "print(automl_bc.sprint_statistics())\n",
    "print(' ')\n",
    "print(\"Accuracy score BC Holdout Parallel:\")\n",
    "print(sklearn.metrics.accuracy_score(y_bc_test, \\\n",
    "                                     predictions_bc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save Ensemble to Disk\n",
    "\n",
    "In the specific case of [scikit-learn](https://scikit-learn.org/stable/modules/model_persistence.html#persistence-example), it may be better to use joblib’s replacement of pickle (dump & load), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autosklearn_bc.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(automl_bc, 'autosklearn_bc.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Domino Stats File\n",
    "\n",
    "To keep things simple, we pick one of the hd models. Saving stats to this file [allows Domino to track and trend them in the Experiment Manager](https://support.dominodatalab.com/hc/en-us/articles/204348169-Diagnostic-statistics-with-dominostats-json) when this notebook is run as a batch or scheduled job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_acc = sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                        predictions_hd_ohe_p)\n",
    "bc_acc = sklearn.metrics.accuracy_score(y_bc_test, \\\n",
    "                                        predictions_bc)\n",
    "\n",
    "import json\n",
    "with open('dominostats.json', 'w') as f:\n",
    "    f.write(json.dumps( {\"HD_ACC\": hd_acc, \"BC_ACC\": bc_acc}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
